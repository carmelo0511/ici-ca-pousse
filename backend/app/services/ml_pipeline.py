import numpy as np
import pandas as pd
from typing import Dict, List, Optional
import logging
from models.ensemble_model import AdvancedEnsembleModel
from services.simple_feature_engineering import SimpleFeatureEngineer
from services.plateau_detection import AdvancedPlateauDetector
from utils.mlflow_tracker import MLflowTracker

logger = logging.getLogger(__name__)

class MLPipeline:
    def __init__(self, config: Dict = None):
        self.config = config or {}
        
        try:
            self.feature_engineer = SimpleFeatureEngineer()
            self.ensemble_model = AdvancedEnsembleModel()
            self.plateau_detector = AdvancedPlateauDetector()
            self.mlflow_tracker = MLflowTracker("ici-ca-pousse-ml")
            logger.info("Pipeline ML initialis√© avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation du pipeline: {e}")
            raise
        
        self.is_initialized = False
        self.is_trained = False
        
    async def initialize(self, workout_data: List[Dict], user_profile: Dict = None):
        """Initialise le pipeline avec les donn√©es utilisateur"""
        try:
            logger.info("Initialisation du pipeline ML...")
            
            if not workout_data:
                return {"success": False, "error": "Aucune donn√©e d'entra√Ænement fournie"}
            
            # Feature engineering
            features = self.feature_engineer.extract_features(workout_data, user_profile or {})
            
            if features.empty:
                return {"success": False, "error": "Impossible d'extraire des features"}
            
            # Pr√©parer les targets (poids futurs)
            targets = self._prepare_targets(workout_data)
            
            if len(targets) == 0:
                return {"success": False, "error": "Impossible de pr√©parer les targets"}
            
            # V√©rifier la coh√©rence des donn√©es
            if len(features) != len(targets):
                logger.warning(f"Incoh√©rence des donn√©es: {len(features)} features vs {len(targets)} targets")
                min_len = min(len(features), len(targets))
                features = features.iloc[:min_len]
                targets = targets[:min_len]
            
            # Entra√Æner les mod√®les
            training_result = await self.train_models(features, targets)
            
            self.is_initialized = True
            logger.info("Pipeline ML initialis√© avec succ√®s")
            return {"success": True, "message": "Pipeline initialis√© avec succ√®s", "training_result": training_result}
            
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation: {e}")
            return {"success": False, "error": str(e)}
    
    async def predict(self, exercise_name: str, user_data: Dict, workout_history: List[Dict]) -> Dict:
        """Pr√©diction de poids avec pipeline ML avanc√©"""
        try:
            logger.info(f"Pr√©diction pour l'exercice: {exercise_name}")
            
            # V√©rifier que nous avons des donn√©es d'historique
            if not workout_history:
                return self._fallback_prediction(exercise_name, user_data, "Aucun historique d'entra√Ænement")
            
            # Feature engineering
            features = self.feature_engineer.extract_features(workout_history, user_data)
            
            if features.empty:
                return self._fallback_prediction(exercise_name, user_data, "Impossible d'extraire les features")
            
            # Pr√©diction avec ensemble si disponible
            if self.is_trained and self.ensemble_model.is_trained:
                try:
                    raw_prediction = self.ensemble_model.predict(features.values)
                    predicted_weight = raw_prediction[0] if len(raw_prediction) > 0 else 0
                except Exception as e:
                    logger.error(f"Erreur lors de la pr√©diction avec l'ensemble: {e}")
                    return self._fallback_prediction(exercise_name, user_data, str(e))
            else:
                return self._fallback_prediction(exercise_name, user_data, "Mod√®les non entra√Æn√©s")
            
            # D√©tection de plateau
            try:
                plateau_analysis = self.plateau_detector.detect_plateaus(workout_history)
            except Exception as e:
                logger.warning(f"Erreur lors de la d√©tection de plateau: {e}")
                plateau_analysis = {"detected": False, "error": str(e)}
            
            # Post-traitement et validation
            current_weight = user_data.get('current_weight', 0)
            validated_prediction = self._validate_prediction(predicted_weight, current_weight)
            
            # Calculer la confiance
            confidence = self._calculate_confidence(features, validated_prediction, current_weight)
            
            # Log to MLflow
            try:
                if self.mlflow_tracker.is_available():
                    self.mlflow_tracker.log_prediction({
                        "exercise_name": exercise_name,
                        "prediction": validated_prediction,
                        "confidence": confidence,
                        "raw_prediction": predicted_weight
                    })
            except Exception as e:
                logger.warning(f"Erreur lors du logging MLflow: {e}")
            
            return {
                "exercise_name": exercise_name,
                "predicted_weight": validated_prediction,
                "confidence": confidence,
                "plateau_analysis": plateau_analysis,
                "model_used": "python_ensemble",
                "features_used": len(features.columns),
                "recommendations": self._generate_recommendations(validated_prediction, current_weight, plateau_analysis)
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction: {e}")
            return self._fallback_prediction(exercise_name, user_data, str(e))
    
    async def train_models(self, features: pd.DataFrame, targets: np.ndarray, retrain: bool = False):
        """Entra√Ænement des mod√®les avec nouvelles donn√©es"""
        try:
            logger.info(f"Entra√Ænement des mod√®les avec {len(features)} √©chantillons")
            
            if len(features) < 2:
                logger.warning("Pas assez de donn√©es pour l'entra√Ænement")
                return {"error": "Pas assez de donn√©es pour l'entra√Ænement"}
            
            # V√©rifier et nettoyer les donn√©es
            features_clean = features.fillna(0)
            targets_clean = np.nan_to_num(targets)
            
            # Utiliser MLflow si disponible
            if self.mlflow_tracker.is_available():
                with self.mlflow_tracker.start_run("model_training"):
                    # Log des param√®tres
                    self.mlflow_tracker.log_params({
                        "n_samples": len(features_clean),
                        "n_features": len(features_clean.columns),
                        "retrain": retrain
                    })
                    
                    # Entra√Æner l'ensemble
                    training_result = self.ensemble_model.train(
                        features_clean.values, 
                        targets_clean,
                        feature_names=list(features_clean.columns)
                    )
                    
                    # Log des m√©triques
                    if training_result:
                        metrics = {}
                        for model_name, scores in training_result.items():
                            metrics[f"{model_name}_mse"] = scores.get("mse", 0)
                            metrics[f"{model_name}_r2"] = scores.get("r2", 0)
                        self.mlflow_tracker.log_metrics(metrics)
            else:
                # Entra√Ænement sans MLflow
                training_result = self.ensemble_model.train(
                    features_clean.values, 
                    targets_clean,
                    feature_names=list(features_clean.columns)
                )
            
            self.is_trained = True
            logger.info("Entra√Ænement termin√© avec succ√®s")
            return training_result
            
        except Exception as e:
            logger.error(f"Erreur lors de l'entra√Ænement: {e}")
            raise Exception(f"Erreur lors de l'entra√Ænement: {str(e)}")
    
    async def train(self, user_id: str, new_data: List[Dict], retrain: bool = False):
        """Interface pour l'entra√Ænement via API"""
        try:
            logger.info(f"Entra√Ænement pour l'utilisateur {user_id}")
            
            if not new_data:
                return {"error": "Aucune nouvelle donn√©e fournie"}
            
            # Extraire les features des nouvelles donn√©es
            features = self.feature_engineer.extract_features(new_data, {})
            
            if features.empty:
                return {"error": "Impossible d'extraire les features des nouvelles donn√©es"}
            
            # Pr√©parer les targets
            targets = self._prepare_targets(new_data)
            
            if len(targets) == 0:
                return {"error": "Impossible de pr√©parer les targets"}
            
            # Entra√Æner
            training_result = await self.train_models(features, targets, retrain)
            
            return {
                "success": True,
                "user_id": user_id,
                "samples_trained": len(features),
                "training_result": training_result
            }
            
        except Exception as e:
            logger.error(f"Erreur lors de l'entra√Ænement utilisateur: {e}")
            return {"error": str(e)}
    
    def get_performance_metrics(self) -> Dict:
        """R√©cup√®re les m√©triques de performance"""
        if not self.is_trained:
            return {"error": "Mod√®les non entra√Æn√©s"}
        
        try:
            return {
                "ensemble_r2": self.ensemble_model.get_r2_score(),
                "ensemble_mse": self.ensemble_model.get_mse_score(),
                "feature_importance": self.ensemble_model.get_feature_importance(),
                "model_weights": self.ensemble_model.get_ensemble_weights(),
                "training_history": self.ensemble_model.get_training_history()
            }
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des m√©triques: {e}")
            return {"error": str(e)}
    
    def get_feature_importance(self) -> Dict:
        """R√©cup√®re l'importance des features"""
        if not self.is_trained:
            return {}
        
        try:
            return self.ensemble_model.get_feature_importance()
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de l'importance des features: {e}")
            return {}
    
    def get_training_history(self) -> Dict:
        """R√©cup√®re l'historique d'entra√Ænement"""
        if not self.is_trained:
            return {}
        
        try:
            return self.ensemble_model.get_training_history()
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de l'historique: {e}")
            return {}
    
    def get_prediction_accuracy(self) -> Dict:
        """R√©cup√®re la pr√©cision des pr√©dictions"""
        if not self.is_trained:
            return {}
        
        try:
            history = self.ensemble_model.get_training_history()
            return {
                "r2_score": history.get("ensemble_r2", 0),
                "mse_score": history.get("ensemble_mse", 0),
                "model_count": len(self.ensemble_model.models),
                "trained_samples": history.get("n_samples", 0)
            }
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration de la pr√©cision: {e}")
            return {}
    
    def get_model_info(self) -> Dict:
        """R√©cup√®re les informations sur les mod√®les"""
        return {
            "is_trained": self.is_trained,
            "is_initialized": self.is_initialized,
            "model_count": len(self.ensemble_model.models) if hasattr(self.ensemble_model, 'models') else 0,
            "mlflow_available": self.mlflow_tracker.is_available(),
            "features_available": hasattr(self.feature_engineer, 'feature_config')
        }
    
    def _prepare_targets(self, workout_data: List[Dict]) -> np.ndarray:
        """Pr√©pare les targets pour l'entra√Ænement"""
        try:
            weights = []
            
            for workout in workout_data:
                for exercise in workout.get('exercises', []):
                    for set_data in exercise.get('sets', []):
                        weight = set_data.get('weight')
                        if weight is not None and weight > 0:
                            weights.append(float(weight))
            
            if len(weights) < 2:
                return np.array([])
            
            # Cr√©er des targets bas√©s sur la progression
            targets = []
            for i in range(len(weights) - 1):
                targets.append(weights[i + 1])  # Le poids suivant comme target
            
            targets_array = np.array(targets)
            logger.info(f"Targets pr√©par√©s: {len(targets_array)} valeurs, shape: {targets_array.shape}")
            return targets_array
            
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©paration des targets: {e}")
            return np.array([])
    
    def _validate_prediction(self, prediction: float, current_weight: float) -> float:
        """Valide et ajuste la pr√©diction selon les contraintes de musculation"""
        try:
            if current_weight <= 0:
                return max(5.0, prediction)  # Poids minimum raisonnable
            
            # Contraintes de musculation
            min_increment = 0.5
            max_increment = 10.0
            realistic_progression = 2.5
            
            increment = prediction - current_weight
            
            # Ajuster selon les contraintes
            if increment < 0:
                increment = min_increment  # Pas de r√©gression
            elif increment > max_increment:
                increment = realistic_progression
            
            # Ajuster aux paliers disponibles (poids de musculation standard)
            weight_plateaus = [0.5, 1.0, 1.25, 2.5, 5.0]
            closest_plateau = min(weight_plateaus, key=lambda x: abs(x - increment))
            
            return current_weight + closest_plateau
            
        except Exception as e:
            logger.error(f"Erreur lors de la validation de la pr√©diction: {e}")
            return current_weight + 2.5  # Incr√©ment par d√©faut
    
    def _calculate_confidence(self, features: pd.DataFrame, prediction: float, current_weight: float) -> float:
        """Calcule la confiance de la pr√©diction"""
        try:
            confidence_factors = []
            
            # Facteur bas√© sur la quantit√© de donn√©es
            data_quality = min(1.0, len(features) / 10)
            confidence_factors.append(data_quality)
            
            # Facteur bas√© sur la coh√©rence de la pr√©diction
            if current_weight > 0:
                increment = abs(prediction - current_weight)
                if increment <= 5.0:  # Incr√©ment raisonnable
                    confidence_factors.append(0.8)
                else:
                    confidence_factors.append(0.4)
            
            # Facteur bas√© sur l'entra√Ænement du mod√®le
            if self.is_trained:
                r2_score = self.ensemble_model.get_r2_score()
                confidence_factors.append(max(0.3, min(0.9, r2_score)))
            else:
                confidence_factors.append(0.3)
            
            return max(0.1, min(0.95, np.mean(confidence_factors)))
            
        except Exception as e:
            logger.error(f"Erreur lors du calcul de la confiance: {e}")
            return 0.5
    
    def _generate_recommendations(self, prediction: float, current_weight: float, plateau_analysis: Dict) -> List[str]:
        """G√©n√®re des recommandations personnalis√©es"""
        try:
            recommendations = []
            
            increment = prediction - current_weight
            
            # Recommandations bas√©es sur la pr√©diction
            if increment > 0:
                recommendations.append(f"Poids recommand√©: {prediction:.1f}kg (+{increment:.1f}kg)")
            else:
                recommendations.append(f"Maintenir le poids actuel: {current_weight:.1f}kg")
            
            # Recommandations bas√©es sur les plateaux
            if plateau_analysis.get("severity_score", 0) > 0.7:
                recommendations.append("üö® Plateau d√©tect√© - Varier les exercices")
                recommendations.append("üìà Augmenter l'intensit√© ou le volume")
            elif plateau_analysis.get("severity_score", 0) > 0.4:
                recommendations.append("‚ö†Ô∏è Progression ralentie - Revoir la programmation")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration des recommandations: {e}")
            return [f"Poids recommand√©: {prediction:.1f}kg"]
    
    def _fallback_prediction(self, exercise_name: str, user_data: Dict, error: str = None) -> Dict:
        """Pr√©diction de fallback en cas d'erreur"""
        try:
            current_weight = user_data.get('current_weight', 0)
            fallback_increment = 2.5  # Incr√©ment par d√©faut
            
            if current_weight <= 0:
                predicted_weight = 10.0  # Poids de d√©part par d√©faut
            else:
                predicted_weight = current_weight + fallback_increment
            
            return {
                "exercise_name": exercise_name,
                "predicted_weight": predicted_weight,
                "confidence": 0.3,
                "plateau_analysis": {"detected": False},
                "model_used": "fallback",
                "error": error,
                "recommendations": [
                    f"Poids recommand√©: {predicted_weight:.1f}kg",
                    "Pr√©diction de fallback - Collecter plus de donn√©es"
                ]
            }
            
        except Exception as e:
            logger.error(f"Erreur dans le fallback: {e}")
            return {
                "exercise_name": exercise_name,
                "predicted_weight": 10.0,
                "confidence": 0.1,
                "plateau_analysis": {"detected": False},
                "model_used": "emergency_fallback",
                "error": str(e),
                "recommendations": ["Erreur de pr√©diction - Utiliser poids par d√©faut"]
            }